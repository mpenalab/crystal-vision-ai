version: '3.8'

services:
  app:
    build: .
    container_name: steel_app
    shm_size: '2gb'
    volumes:
      - .:/app
    stdin_open: true
    tty: true
    depends_on:
      - mlflow
    networks:
      - cv_network
    command: bash
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - KAGGLE_API_TOKEN=${KAGGLE_API_TOKEN}
      - MLFLOW_TRACKING_URI=http://mlflow:5000 # Lo pasamos como variable

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: steel_mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    networks:
      - cv_network
    command: >
      mlflow server 
      --host 0.0.0.0 
      --port 5000 
      --backend-store-uri sqlite:///mlflow.db 
      --default-artifact-root /mlruns

networks:
  cv_network:
    driver: bridge